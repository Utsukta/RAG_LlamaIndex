{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging,qdrant_client\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader,Settings,StorageContext\n",
    "from llama_index.core.indices.query.query_transform import HyDEQueryTransform\n",
    "from llama_index.core.query_engine import TransformQueryEngine\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter,SemanticSplitterNodeParser\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "from llama_index.core.retrievers import RecursiveRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.schema import IndexNode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader(\"./uploaded_files\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm=Ollama(model=\"llama3\",request_timeout=120.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model=OllamaEmbedding(model_name=\"snowflake-arctic-embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings.text_splitter=SentenceSplitter(chunk_size=1024,chunk_overlap=20)\n",
    "node_parser = SemanticSplitterNodeParser(embed_model=Settings.embed_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "client=qdrant_client.QdrantClient(location=\":memory:\")\n",
    "vector_store=QdrantVectorStore(client=client,collection_name=\"sampledata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context=StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_nodes = node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, node in enumerate(base_nodes):\n",
    "    node.id_ = f\"node-{idx}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_chunk_sizes = [128, 256, 512]\n",
    "sub_node_parsers = [\n",
    "    SentenceSplitter(chunk_size=c, chunk_overlap=20) for c in sub_chunk_sizes\n",
    "]\n",
    "\n",
    "all_nodes = []\n",
    "for base_node in base_nodes:\n",
    "    for n in sub_node_parsers:\n",
    "        sub_nodes = n.get_nodes_from_documents([base_node])\n",
    "        sub_inodes = [\n",
    "            IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes\n",
    "        ]\n",
    "        all_nodes.extend(sub_inodes)\n",
    "\n",
    "    # also add original node to node\n",
    "    original_node = IndexNode.from_text_node(base_node, base_node.node_id)\n",
    "    all_nodes.append(original_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes_dict = {n.node_id: n for n in all_nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Point id node-0 is not a valid UUID",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/LLAMAINDEX_RAG/lib/python3.12/site-packages/qdrant_client/local/local_collection.py:1336\u001b[0m, in \u001b[0;36mLocalCollection._upsert_point\u001b[0;34m(self, point)\u001b[0m\n\u001b[1;32m   1335\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1336\u001b[0m     _uuid \u001b[39m=\u001b[39m uuid\u001b[39m.\u001b[39;49mUUID(point\u001b[39m.\u001b[39;49mid)\n\u001b[1;32m   1337\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/LLAMAINDEX_RAG/lib/python3.12/uuid.py:178\u001b[0m, in \u001b[0;36mUUID.__init__\u001b[0;34m(self, hex, bytes, bytes_le, fields, int, version, is_safe)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mhex\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39m32\u001b[39m:\n\u001b[0;32m--> 178\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mbadly formed hexadecimal UUID string\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    179\u001b[0m \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m int_(\u001b[39mhex\u001b[39m, \u001b[39m16\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: badly formed hexadecimal UUID string",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/utsuktakhatri/RAG_LlamaIndex/chunk_references.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/utsuktakhatri/RAG_LlamaIndex/chunk_references.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m vector_index_chunk \u001b[39m=\u001b[39m VectorStoreIndex(all_nodes, embed_model\u001b[39m=\u001b[39;49mSettings\u001b[39m.\u001b[39;49membed_model, storage_context\u001b[39m=\u001b[39;49mstorage_context)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/LLAMAINDEX_RAG/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:75\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[0;34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, service_context, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embed_model \u001b[39m=\u001b[39m (\n\u001b[1;32m     69\u001b[0m     resolve_embed_model(embed_model, callback_manager\u001b[39m=\u001b[39mcallback_manager)\n\u001b[1;32m     70\u001b[0m     \u001b[39mif\u001b[39;00m embed_model\n\u001b[1;32m     71\u001b[0m     \u001b[39melse\u001b[39;00m embed_model_from_settings_or_context(Settings, service_context)\n\u001b[1;32m     72\u001b[0m )\n\u001b[1;32m     74\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insert_batch_size \u001b[39m=\u001b[39m insert_batch_size\n\u001b[0;32m---> 75\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     76\u001b[0m     nodes\u001b[39m=\u001b[39;49mnodes,\n\u001b[1;32m     77\u001b[0m     index_struct\u001b[39m=\u001b[39;49mindex_struct,\n\u001b[1;32m     78\u001b[0m     service_context\u001b[39m=\u001b[39;49mservice_context,\n\u001b[1;32m     79\u001b[0m     storage_context\u001b[39m=\u001b[39;49mstorage_context,\n\u001b[1;32m     80\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[1;32m     81\u001b[0m     objects\u001b[39m=\u001b[39;49mobjects,\n\u001b[1;32m     82\u001b[0m     callback_manager\u001b[39m=\u001b[39;49mcallback_manager,\n\u001b[1;32m     83\u001b[0m     transformations\u001b[39m=\u001b[39;49mtransformations,\n\u001b[1;32m     84\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     85\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/LLAMAINDEX_RAG/lib/python3.12/site-packages/llama_index/core/indices/base.py:94\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[0;34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, service_context, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m index_struct \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     nodes \u001b[39m=\u001b[39m nodes \u001b[39mor\u001b[39;00m []\n\u001b[0;32m---> 94\u001b[0m     index_struct \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_index_from_nodes(\n\u001b[1;32m     95\u001b[0m         nodes \u001b[39m+\u001b[39;49m objects  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[1;32m     96\u001b[0m     )\n\u001b[1;32m     97\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct \u001b[39m=\u001b[39m index_struct\n\u001b[1;32m     98\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_storage_context\u001b[39m.\u001b[39mindex_store\u001b[39m.\u001b[39madd_index_struct(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/LLAMAINDEX_RAG/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:308\u001b[0m, in \u001b[0;36mVectorStoreIndex.build_index_from_nodes\u001b[0;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[1;32m    301\u001b[0m     node\u001b[39m.\u001b[39mget_content(metadata_mode\u001b[39m=\u001b[39mMetadataMode\u001b[39m.\u001b[39mEMBED) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m nodes\n\u001b[1;32m    302\u001b[0m ):\n\u001b[1;32m    303\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    304\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot build index from nodes with no content. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure all nodes have content.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m     )\n\u001b[0;32m--> 308\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_index_from_nodes(nodes, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minsert_kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/LLAMAINDEX_RAG/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:280\u001b[0m, in \u001b[0;36mVectorStoreIndex._build_index_from_nodes\u001b[0;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m     run_async_tasks(tasks)\n\u001b[1;32m    279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 280\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_nodes_to_index(\n\u001b[1;32m    281\u001b[0m         index_struct,\n\u001b[1;32m    282\u001b[0m         nodes,\n\u001b[1;32m    283\u001b[0m         show_progress\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_show_progress,\n\u001b[1;32m    284\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minsert_kwargs,\n\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[39mreturn\u001b[39;00m index_struct\n",
      "File \u001b[0;32m/opt/anaconda3/envs/LLAMAINDEX_RAG/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:234\u001b[0m, in \u001b[0;36mVectorStoreIndex._add_nodes_to_index\u001b[0;34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mfor\u001b[39;00m nodes_batch \u001b[39min\u001b[39;00m iter_batch(nodes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insert_batch_size):\n\u001b[1;32m    233\u001b[0m     nodes_batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_node_with_embedding(nodes_batch, show_progress)\n\u001b[0;32m--> 234\u001b[0m     new_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vector_store\u001b[39m.\u001b[39;49madd(nodes_batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minsert_kwargs)\n\u001b[1;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39mstores_text \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store_nodes_override:\n\u001b[1;32m    237\u001b[0m         \u001b[39m# NOTE: if the vector store doesn't store text,\u001b[39;00m\n\u001b[1;32m    238\u001b[0m         \u001b[39m# we need to add the nodes to the index struct and document store\u001b[39;00m\n\u001b[1;32m    239\u001b[0m         \u001b[39mfor\u001b[39;00m node, new_id \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(nodes_batch, new_ids):\n\u001b[1;32m    240\u001b[0m             \u001b[39m# NOTE: remove embedding from node to avoid duplication\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/LLAMAINDEX_RAG/lib/python3.12/site-packages/llama_index/vector_stores/qdrant/base.py:293\u001b[0m, in \u001b[0;36mQdrantVectorStore.add\u001b[0;34m(self, nodes, **add_kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m sparse_vector_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparse_vector_name()\n\u001b[1;32m    291\u001b[0m points, ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_points(nodes, sparse_vector_name)\n\u001b[0;32m--> 293\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mupload_points(\n\u001b[1;32m    294\u001b[0m     collection_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollection_name,\n\u001b[1;32m    295\u001b[0m     points\u001b[39m=\u001b[39;49mpoints,\n\u001b[1;32m    296\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[1;32m    297\u001b[0m     parallel\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparallel,\n\u001b[1;32m    298\u001b[0m     max_retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    299\u001b[0m     wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    300\u001b[0m )\n\u001b[1;32m    302\u001b[0m \u001b[39mreturn\u001b[39;00m ids\n",
      "File \u001b[0;32m/opt/anaconda3/envs/LLAMAINDEX_RAG/lib/python3.12/site-packages/qdrant_client/qdrant_client.py:1933\u001b[0m, in \u001b[0;36mQdrantClient.upload_points\u001b[0;34m(self, collection_name, points, batch_size, parallel, method, max_retries, wait, shard_key_selector, **kwargs)\u001b[0m\n\u001b[1;32m   1908\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Upload points to the collection\u001b[39;00m\n\u001b[1;32m   1909\u001b[0m \n\u001b[1;32m   1910\u001b[0m \u001b[39mSimilar to `upload_collection` method, but operates with points, rather than vector and payload individually.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1929\u001b[0m \n\u001b[1;32m   1930\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1931\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(kwargs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown arguments: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1933\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mupload_points(\n\u001b[1;32m   1934\u001b[0m     collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m   1935\u001b[0m     points\u001b[39m=\u001b[39;49mpoints,\n\u001b[1;32m   1936\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1937\u001b[0m     parallel\u001b[39m=\u001b[39;49mparallel,\n\u001b[1;32m   1938\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m   1939\u001b[0m     max_retries\u001b[39m=\u001b[39;49mmax_retries,\n\u001b[1;32m   1940\u001b[0m     wait\u001b[39m=\u001b[39;49mwait,\n\u001b[1;32m   1941\u001b[0m     shard_key_selector\u001b[39m=\u001b[39;49mshard_key_selector,\n\u001b[1;32m   1942\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/LLAMAINDEX_RAG/lib/python3.12/site-packages/qdrant_client/local/qdrant_local.py:722\u001b[0m, in \u001b[0;36mQdrantLocal.upload_points\u001b[0;34m(self, collection_name, points, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupload_points\u001b[39m(\n\u001b[1;32m    720\u001b[0m     \u001b[39mself\u001b[39m, collection_name: \u001b[39mstr\u001b[39m, points: Iterable[types\u001b[39m.\u001b[39mPointStruct], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any\n\u001b[1;32m    721\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 722\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_upload_points(collection_name, points)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/LLAMAINDEX_RAG/lib/python3.12/site-packages/qdrant_client/local/qdrant_local.py:736\u001b[0m, in \u001b[0;36mQdrantLocal._upload_points\u001b[0;34m(self, collection_name, points)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_upload_points\u001b[39m(\n\u001b[1;32m    731\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    732\u001b[0m     collection_name: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    733\u001b[0m     points: Iterable[Union[types\u001b[39m.\u001b[39mPointStruct, types\u001b[39m.\u001b[39mRecord]],\n\u001b[1;32m    734\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m     collection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_collection(collection_name)\n\u001b[0;32m--> 736\u001b[0m     collection\u001b[39m.\u001b[39;49mupsert(\n\u001b[1;32m    737\u001b[0m         [\n\u001b[1;32m    738\u001b[0m             rest_models\u001b[39m.\u001b[39;49mPointStruct(\n\u001b[1;32m    739\u001b[0m                 \u001b[39mid\u001b[39;49m\u001b[39m=\u001b[39;49mpoint\u001b[39m.\u001b[39;49mid,\n\u001b[1;32m    740\u001b[0m                 vector\u001b[39m=\u001b[39;49mpoint\u001b[39m.\u001b[39;49mvector \u001b[39mor\u001b[39;49;00m {},\n\u001b[1;32m    741\u001b[0m                 payload\u001b[39m=\u001b[39;49mpoint\u001b[39m.\u001b[39;49mpayload \u001b[39mor\u001b[39;49;00m {},\n\u001b[1;32m    742\u001b[0m             )\n\u001b[1;32m    743\u001b[0m             \u001b[39mfor\u001b[39;49;00m point \u001b[39min\u001b[39;49;00m points\n\u001b[1;32m    744\u001b[0m         ]\n\u001b[1;32m    745\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/LLAMAINDEX_RAG/lib/python3.12/site-packages/qdrant_client/local/local_collection.py:1370\u001b[0m, in \u001b[0;36mLocalCollection.upsert\u001b[0;34m(self, points)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(points, \u001b[39mlist\u001b[39m):\n\u001b[1;32m   1369\u001b[0m     \u001b[39mfor\u001b[39;00m point \u001b[39min\u001b[39;00m points:\n\u001b[0;32m-> 1370\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_upsert_point(point)\n\u001b[1;32m   1371\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(points, models\u001b[39m.\u001b[39mBatch):\n\u001b[1;32m   1372\u001b[0m     batch \u001b[39m=\u001b[39m points\n",
      "File \u001b[0;32m/opt/anaconda3/envs/LLAMAINDEX_RAG/lib/python3.12/site-packages/qdrant_client/local/local_collection.py:1338\u001b[0m, in \u001b[0;36mLocalCollection._upsert_point\u001b[0;34m(self, point)\u001b[0m\n\u001b[1;32m   1336\u001b[0m         _uuid \u001b[39m=\u001b[39m uuid\u001b[39m.\u001b[39mUUID(point\u001b[39m.\u001b[39mid)\n\u001b[1;32m   1337\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1338\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPoint id \u001b[39m\u001b[39m{\u001b[39;00mpoint\u001b[39m.\u001b[39mid\u001b[39m}\u001b[39;00m\u001b[39m is not a valid UUID\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(point\u001b[39m.\u001b[39mvector, \u001b[39mdict\u001b[39m):\n\u001b[1;32m   1341\u001b[0m     updated_sparse_vectors \u001b[39m=\u001b[39m {}\n",
      "\u001b[0;31mValueError\u001b[0m: Point id node-0 is not a valid UUID"
     ]
    }
   ],
   "source": [
    "vector_index_chunk = VectorStoreIndex(all_nodes, embed_model=Settings.embed_model, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index_chunk.storage_context.persist(persist_dir=\"db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_chunk = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever_chunk},\n",
    "    node_dict=all_nodes_dict,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: Applications of GAN\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-41\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id node-41: Applications of GAN\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** node-41<br>**Similarity:** 0.725268165083198<br>**Text:** 67, pp. 23 −31, Jul.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = retriever_chunk.retrieve(\n",
    "    \"Applications of GAN\"\n",
    ")\n",
    "for node in nodes:\n",
    "    display_source_node(node, source_length=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_chunk = RetrieverQueryEngine.from_args(retriever_chunk, llm=Settings.llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: list all applications of GAN\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-19\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id node-19: list all applications of GAN\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: list all applications of GAN\n",
      "\u001b[0mINFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "Based on the provided context, here are the listed applications of GAN:\n",
      "\n",
      "1. Generating photorealistic images.\n",
      "2. Tackling the problem of insufficient training samples for supervised or semi-supervised learning.\n",
      "3. Speech and language processing, such as generating dialogues.\n",
      "4. Image super-resolution (SRGAN).\n",
      "5. Generating high-quality face samples at resolutions of 128×128 (BEGAN).\n",
      "6. Generating driving scenarios.\n",
      "7. Learning from both real images and synthetic images for accurate eye detection (Gou et al.).\n",
      "8. Bridging the gap between synthetic and real image datasets using simulated and unsupervised learning (SimGAN).\n",
      "\n",
      "Note that these applications are mentioned in the provided context as examples of GAN's capabilities and potential uses.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine_chunk.query(\n",
    "    \"list all applications of GAN\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents=documents,storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.storage_context.persist(persist_dir=\"db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine=index.as_query_engine(response_mode=\"refine\",verbose=True,similarity_top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"code to add two numbers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "   \"You are an AI assistant specialized in providing information from the uploaded document. \"\n",
    "   \"Please ensure that your responses are strictly derived from the content of the document. \"\n",
    "   \"If the information is not found in the document, please indicate that explicitly.\"\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_with_prompt=f\"{system_prompt}\\nUser query:{query_str}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I'm not finding any information related to adding two numbers in the provided context. The uploaded document appears to be about Customer Identification and KYC norms, and it does not contain any mathematical operations or coding examples. Therefore, I must indicate that the requested code is not found in the document. If you're looking for help with a specific math problem or coding task, feel free to ask, and I'll do my best to assist you within the context of this uploaded document!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(query_with_prompt)\n",
    "display(Markdown(f\"{response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I'm happy to help! However, I must clarify that the provided context information does not contain any relevant information about adding two numbers or performing mathematical operations. The context appears to be focused on customer identification and Know Your Customer (KYC) norms in banking and financial services.\n",
       "\n",
       "Since the query \"code to add two numbers\" is unrelated to the provided context, I will explicitly indicate that the answer cannot be found within the document."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyde = HyDEQueryTransform(include_original=True)\n",
    "hyde_query_engine = TransformQueryEngine(query_engine, hyde)\n",
    "response = hyde_query_engine.query(query_with_prompt)\n",
    "display(Markdown(f\"{response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query_bundle = hyde(query_str)\n",
    "hyde_doc = query_bundle.embedding_strs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The humble printed cheque form has been a stalwart in the world of financial transactions for centuries. Despite the rise of digital payment methods, printed cheques continue to offer several key merits that make them an attractive option for many individuals and businesses.\\n\\nFirstly, printed cheques provide a tangible record of a transaction, allowing both the payer and payee to verify the details of the payment. This physical evidence can be invaluable in situations where disputes arise or when auditing financial records is necessary. Furthermore, printed cheques are resistant to hacking and cyber attacks, providing an added layer of security for sensitive transactions.\\n\\nAnother significant merit of printed cheque forms is their flexibility. Unlike digital payments, which may have limited transaction amounts or require specific bank accounts, printed cheques can be customized to suit individual needs. For instance, businesses may use printed cheques to make bulk payments or to pay vendors who do not accept electronic payments. Additionally, printed cheques offer a way for individuals to make large or unusual purchases that exceed the limits of digital payment methods.\\n\\nPrinted cheque forms also possess a certain level of prestige and formality, making them suitable for special occasions or business transactions. The physical act of writing and signing a cheque can carry a sense of importance and commitment, which may be lacking in digital payments. Moreover, printed cheques can be personalized with company logos or signatures, providing an opportunity to showcase one's brand identity.\\n\\nIn conclusion, the merits of printed cheque forms lie in their tangible nature, flexibility, security, and formality. While digital payment methods have certainly streamlined financial transactions, printed cheques continue to offer a reliable and practical option for individuals and businesses seeking to conduct secure and transparent financial dealings.\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyde_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLAMAINDEX_RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
